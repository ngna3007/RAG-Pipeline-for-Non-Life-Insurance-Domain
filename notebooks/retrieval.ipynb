{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Initial Setup and Configuration\n",
    " This block sets up the environment, imports the needed libraries and also configures the connection to Qdrant (our vector database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: RobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import re\n",
    "import dotenv\n",
    "from typing import List, Dict\n",
    "import unicodedata\n",
    "\n",
    "#load environment variables from .env file\n",
    "dotenv.load_dotenv(\".env.local\")\n",
    "\n",
    "#qdrant configuration\n",
    "QDRANT_URL = os.getenv('QDRANT_URL')\n",
    "QDRANT_API_KEY = os.getenv('QDRANT_API_KEY')\n",
    "COLLECTION_NAME = 'legal_docs'\n",
    "\n",
    "#initialize global variables\n",
    "client = QdrantClient(\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "#load model\n",
    "model = SentenceTransformer('keepitreal/vietnamese-sbert')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DDefines a set of common viet stopwards that will be filtered out in text processing bc they dont carry much meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Vietnamese stopwords\n",
    "VIETNAMESE_STOPWORDS = {\n",
    "    'và', 'của', 'cho', 'là', 'để', 'trong', 'với', 'các', 'có', 'được', \n",
    "    'tại', 'về', 'từ', 'theo', 'đến', 'không', 'những', 'này', 'đó', 'khi'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This function normalizes viet text by removing the accent marks from the viet characters and converts all the text in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vietnamese_text(text):\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "    text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This function identifies and extracts the specific entities from user queries, eg. references to dieu and thong tu and important keywords from the query. This function just uses regular expressions to indentify the patterns and then it returns a dictionary of extracted entities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_query_entities(query):\n",
    "    query = query.lower()\n",
    "    entities = {}\n",
    "    \n",
    "    #find dieu references (more flexible patterns)\n",
    "    dieu_patterns = [\n",
    "        r'điều\\s+(\\d+)',  #standard format: Điều 4\n",
    "        r'điều\\s+(\\d+)\\s*[,\\.]\\s*điều\\s+(\\d+)',  #multiple, eg. Điều 2, Điều 3\n",
    "        r'điều\\s*(\\d+)[-–]\\s*(\\d+)',  #range, eg. Điều 4-6\n",
    "    ]\n",
    "    \n",
    "    dieu_matches = []\n",
    "    for pattern in dieu_patterns:\n",
    "        matches = re.findall(pattern, query)\n",
    "        if matches:\n",
    "            #handle tuples from multiple capturing groups\n",
    "            for match in matches:\n",
    "                if isinstance(match, tuple):\n",
    "                    dieu_matches.extend(list(match))\n",
    "                else:\n",
    "                    dieu_matches.append(match)\n",
    "    \n",
    "    if dieu_matches:\n",
    "        entities['dieu'] = list(set(dieu_matches))  #remove duplicates\n",
    "    \n",
    "    #find tt references (more flexible patterns)\n",
    "    tt_patterns = [\n",
    "        r'thông\\s+tư\\s+(?:số\\s+)?(\\d+)',  #standard, eg. Thông tư 67\n",
    "        r'tt\\s*(\\d+)',  #abbreviated, eg. TT67\n",
    "        r'thông\\s+tư\\s+(?:số\\s+)?(\\d+)/\\d+/[\\w-]+',  #full reference with year and code\n",
    "    ]\n",
    "    \n",
    "    tt_matches = []\n",
    "    for pattern in tt_patterns:\n",
    "        matches = re.findall(pattern, query)\n",
    "        tt_matches.extend(matches)\n",
    "    \n",
    "    if tt_matches:\n",
    "        entities['thong_tu'] = [f\"tt{num}\" for num in set(tt_matches)]  #remove duplicates\n",
    "    \n",
    "    #extract keywords for better context matching\n",
    "    keywords = extract_keywords(query)\n",
    "    if keywords:\n",
    "        entities['keywords'] = keywords\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. extract_keywords extracts the important keywords from the query while it removes entity mentions, filters the stopwords annd returns a list of unique keywords\n",
    "\n",
    " 2. calculate_keyword_match_score calculates a relevance score based on how many keywords from the query appear in a document text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(query, max_keywords=5):\n",
    "    #remove entity mentions to focus on topic\n",
    "    clean_query = re.sub(r'điều\\s+\\d+|thông\\s+tư\\s+\\d+', '', query)\n",
    "    \n",
    "    #simple word tokenization\n",
    "    words = re.findall(r'\\b\\w+\\b', clean_query.lower())\n",
    "    \n",
    "    #filter out stopwords\n",
    "    keywords = [word for word in words if len(word) > 2 and word not in VIETNAMESE_STOPWORDS]\n",
    "    \n",
    "    #return unique keywords\n",
    "    return list(set(keywords))[:max_keywords]\n",
    "\n",
    "def calculate_keyword_match_score(keywords, text):\n",
    "    if not keywords:\n",
    "        return 1.0  #no keywords to match\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    matched_keywords = sum(keyword in text_lower for keyword in keywords)\n",
    "    \n",
    "    #calculate score based on proportion of matched keywords\n",
    "    if matched_keywords == 0:\n",
    "        return 0.6  #base score if no matches\n",
    "    \n",
    "    #higher score for more keyword matches\n",
    "    return 0.7 + (0.3 * matched_keywords / len(keywords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#this function filters out search results to strictly match the entity requirements. basically, it only returns results that match all the specified entities (like dieu and thong tu). fro example if a user asks about \"dieu 4 trong tt67\", it will filter out all that doesn't specifically match both the criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict_entity_filter(results, entities):\n",
    "    if not entities or not results:\n",
    "        return results\n",
    "    \n",
    "    filtered_results = []\n",
    "    \n",
    "    for result in results:\n",
    "        metadata = result.payload.get('metadata', {})\n",
    "        \n",
    "        #check for exact matches of dieu if specified\n",
    "        if 'dieu' in entities:\n",
    "            if metadata.get('Điều') not in entities['dieu']:\n",
    "                continue  #skip this result if dieu doesn't match\n",
    "        \n",
    "        #check for exact matches of tt\n",
    "        if 'thong_tu' in entities:\n",
    "            if metadata.get('Thông tư') not in entities['thong_tu']:\n",
    "                continue  #skip\n",
    "        \n",
    "        #if we got here, all entity conditions are satisfied\n",
    "        filtered_results.append(result)\n",
    "    \n",
    "    return filtered_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this function searches with a proper handling of entity requirements\n",
    "1. firstly it encodes the query using the viet language model\n",
    "2. then searches the qdrant db with the encoded vector\n",
    "3. it applies strict filtering based on the extracted entities \n",
    "4. implements a fallback strategy if too few results are found\n",
    "\n",
    "==> this approach is mainly to ensure that the search prioritizes entity matches while still providing relecant results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_with_entities(query, entities, limit):\n",
    "    #vector encoding\n",
    "    query_vector = model.encode(\n",
    "        query,\n",
    "        convert_to_numpy=True,\n",
    "        show_progress_bar=False,\n",
    "        device=device\n",
    "    ).tolist()\n",
    "    \n",
    "    #first approach: get a larger set of results and filter afterward\n",
    "    #semantic searching with payload (metadata)\n",
    "    all_results = client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query_vector=query_vector,\n",
    "        limit=limit * 3,  #get more to allow for filtering\n",
    "        with_payload=True\n",
    "    )\n",
    "    \n",
    "    #apply strict filtering based on entities\n",
    "    if 'dieu' in entities or 'thong_tu' in entities:\n",
    "        filtered_results = strict_entity_filter(all_results, entities)\n",
    "        \n",
    "        #if we have enough results after filtering, return them\n",
    "        if len(filtered_results) >= 3:\n",
    "            return filtered_results\n",
    "        \n",
    "        #or else we'll need to search again with the first entity of each type\n",
    "        #to get more specific results (this is a fallback to ensure we get results)\n",
    "        # ANY not ALL\n",
    "        fallback_entities = {} \n",
    "        if 'dieu' in entities and entities['dieu']:\n",
    "            fallback_entities['dieu'] = [entities['dieu'][0]]\n",
    "        if 'thong_tu' in entities and entities['thong_tu']:\n",
    "            fallback_entities['thong_tu'] = [entities['thong_tu'][0]]\n",
    "        \n",
    "        #if we have specific entities from the query, use them for focused search\n",
    "        if fallback_entities:\n",
    "            #get more focused results with the first entity\n",
    "            focused_results = []\n",
    "            for result in all_results:\n",
    "                metadata = result.payload.get('metadata', {})\n",
    "                \n",
    "                #check if this result matches any of our fallback entities\n",
    "                if ('dieu' in fallback_entities and \n",
    "                    metadata.get('Điều') == fallback_entities['dieu'][0]):\n",
    "                    focused_results.append(result)\n",
    "                elif ('thong_tu' in fallback_entities and \n",
    "                     metadata.get('Thông tư') == fallback_entities['thong_tu'][0]):\n",
    "                    focused_results.append(result)\n",
    "            \n",
    "            #if we found focused results ten return those\n",
    "            if focused_results:\n",
    "                return focused_results\n",
    "    \n",
    "    #return all results if no entity filtering is required or if filtering produced too few results\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " this function just improves the relevance of the results by removing the duplicate content, boosts the scores for exact entity matches, increases the scores for data that matches more keywords, combines vector similary n entity matching scores and sorting the results by final relevance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_results(results, entities, query, limit=5):\n",
    "    if not results:\n",
    "        return []\n",
    "    \n",
    "    processed_results = []\n",
    "    seen_content = set()  #track unique content to remove duplicates\n",
    "    \n",
    "    for result in results:\n",
    "        metadata = result.payload.get('metadata', {})\n",
    "        text = result.payload.get('text', '')\n",
    "        \n",
    "        #skip if we've seen this exact text already (deduplicate)\n",
    "        #use first 100 chars as a content signature\n",
    "        text_signature = text[:100].strip()\n",
    "        if text_signature in seen_content:\n",
    "            continue\n",
    "        seen_content.add(text_signature)\n",
    "        \n",
    "        #base score from vector similarity\n",
    "        base_score = result.score\n",
    "        match_score = 1.0\n",
    "        \n",
    "        #entity matching boost to give high priority to exact matches\n",
    "        if 'dieu' in entities and metadata.get('Điều'):\n",
    "            if metadata.get('Điều') in entities['dieu']:\n",
    "                match_score *= 2.0  #strong boost for exact diu match\n",
    "            else:\n",
    "                match_score *= 0.3  #heavy penalty for non matching dieu\n",
    "        \n",
    "        if 'thong_tu' in entities and metadata.get('Thông tư'):\n",
    "            if metadata.get('Thông tư') in entities['thong_tu']:\n",
    "                match_score *= 2.0  #strong boost\n",
    "            else:\n",
    "                match_score *= 0.3  #heavy penalty\n",
    "        \n",
    "        #content relevance based on keywords\n",
    "        if 'keywords' in entities and entities['keywords']:\n",
    "            keyword_score = calculate_keyword_match_score(entities['keywords'], text)\n",
    "            match_score *= keyword_score\n",
    "        \n",
    "        #calculate the final score as a weighted combination\n",
    "        final_score = (base_score * 0.4) + (match_score * 0.6)  #greater weight to matches\n",
    "        \n",
    "        #create processed result with updated score\n",
    "        processed_result = result\n",
    "        processed_result.score = final_score\n",
    "        processed_results.append(processed_result)\n",
    "    \n",
    "    #sort by final score\n",
    "    processed_results.sort(key=lambda x: x.score, reverse=True)\n",
    "    \n",
    "    return processed_results[:limit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " this function just formats the result text to make it more readable and focusd on the relevat parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_result_text(text, query, entities, max_length=400):\n",
    "    #ff text is shorter than max_length then return it entirely\n",
    "    if len(text) <= max_length:\n",
    "        return text\n",
    "    \n",
    "    #find a good starting point that includes keywords if possible\n",
    "    keywords = entities.get('keywords', [])\n",
    "    start_pos = 0\n",
    "    best_keyword_pos = None\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        keyword_pos = text.lower().find(keyword.lower())\n",
    "        if keyword_pos != -1:\n",
    "            #found a keyword and check if it's a good starting point\n",
    "            if best_keyword_pos is None or (keyword_pos < best_keyword_pos and keyword_pos > 10):\n",
    "                best_keyword_pos = keyword_pos\n",
    "    \n",
    "    #if found a good keyword position then start a bit before it\n",
    "    if best_keyword_pos is not None:\n",
    "        start_pos = max(0, best_keyword_pos - 50)\n",
    "    \n",
    "    #find a good breakpoint (end of sentence or paragraph)\n",
    "    end_pos = min(start_pos + max_length, len(text))\n",
    "    \n",
    "    #try to end at a sentence boundary if possible\n",
    "    sentence_end = text.rfind('. ', start_pos, end_pos)\n",
    "    if sentence_end != -1:\n",
    "        end_pos = sentence_end + 2  #include the period and space\n",
    "    \n",
    "    #add ellipsis if we're truncating\n",
    "    suffix = \"...\" if end_pos < len(text) else \"\"\n",
    "    prefix = \"...\" if start_pos > 0 else \"\"\n",
    "    \n",
    "    return prefix + text[start_pos:end_pos] + suffix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the main function\n",
    "1. extracts the entities and keywords from the query\n",
    "2. performs a search with entity awareness\n",
    "3. applies strict entity filtering\n",
    "4. post processes the results to improve relevance\n",
    "5. formats and displays the results with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_legal_documents(query, limit = 3):\n",
    "    try:\n",
    "        print(f\"Searching for: '{query}'\")\n",
    "        \n",
    "        #extract entities and keywords from query\n",
    "        entities = extract_query_entities(query)\n",
    "        if entities:\n",
    "            entity_str = \", \".join([f\"{k}: {v}\" for k, v in entities.items()]) #key - value pairs\n",
    "            print(f\"Extracted entities: {entity_str}\")\n",
    "        \n",
    "        #do search with entity aware approach\n",
    "        results = search_with_entities(query, entities, 30)\n",
    "        \n",
    "        print(f\"Found {len(results)} initial results\")\n",
    "        \n",
    "        #apply strict entity filtering for dieu and thong tu\n",
    "        if ('dieu' in entities or 'thong_tu' in entities) and results:\n",
    "            results = strict_entity_filter(results, entities)\n",
    "            print(f\"After strict filtering: {len(results)} results\")\n",
    "        \n",
    "        #enhanced post processing with context matching\n",
    "        filtered_results = post_process_results(results, entities, query, limit)\n",
    "        \n",
    "        print(f\"Filtered to {len(filtered_results)} most relevant results\")\n",
    "        \n",
    "        #display results with better formatting\n",
    "        for i, result in enumerate(filtered_results):\n",
    "            print(f\"\\nResult {i+1} [Score: {result.score:.4f}]\")\n",
    "            \n",
    "            metadata = result.payload.get('metadata', {})\n",
    "            thong_tu = metadata.get('Thông tư', 'Unknown')\n",
    "            dieu = metadata.get('Điều', 'Unknown')\n",
    "            \n",
    "            print(f\"From: Thông tư {thong_tu}, Điều {dieu}\")\n",
    "            \n",
    "            #show better formatted text excerpt\n",
    "            text = result.payload.get('text', '')\n",
    "            text_preview = format_result_text(text, query, entities)\n",
    "            print(f\"Text excerpt: {text_preview}\")\n",
    "            print(\"-\" * 80)\n",
    "        \n",
    "        return filtered_results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during search: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_example_queries():\n",
    "    example_queries = [\n",
    "        \"Bảo hiểm xe cơ giới\",\n",
    "        \"Điều 4 quy định về gì\",\n",
    "        \"Điều 2 và Điều 3 trong thông tư 67 bao gồm những gì\",\n",
    "    ]\n",
    "    \n",
    "    for query in example_queries:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"QUERY: '{query}'\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        search_legal_documents(query, limit=3)  #show top 3 results\n",
    "\n",
    "def interactive_search():\n",
    "    print(\"\\n=== Interactive Legal Document Search ===\")\n",
    "    print(\"Type 'exit' to quit.\")\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"\\nEnter your search query: \")\n",
    "        if query.lower() in ('exit', 'quit'):\n",
    "            break\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        search_legal_documents(query, limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Qdrant at: https://c9bb63cf-c1de-4447-b4e6-64c7b7081d74.eu-west-1-0.aws.cloud.qdrant.io\n",
      "\n",
      "================================================================================\n",
      "QUERY: 'Bảo hiểm xe cơ giới'\n",
      "================================================================================\n",
      "Searching for: 'Bảo hiểm xe cơ giới'\n",
      "Extracted entities: keywords: ['giới', 'bảo', 'hiểm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20644\\1910107155.py:12: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  all_results = client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90 initial results\n",
      "Filtered to 3 most relevant results\n",
      "\n",
      "Result 1 [Score: 0.7236]\n",
      "From: Thông tư tt67, Điều 25\n",
      "Text excerpt: Điều 25. Phương pháp, cơ sở tính phí bảo hiểm đối với bảo hiểm xe cơ giới\n",
      "1. ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Result 2 [Score: 0.7176]\n",
      "From: Thông tư tt67, Điều 3\n",
      "Text excerpt: .../NĐ-CP được quy định chi tiết như sau:\n",
      "a) Đối với bảo hiểm nhân thọ: Mẫu số 2-CSDL Phụ lục I ban hành kèm theo Thông tư này;b) Đối với bảo hiểm sức khỏe: Mẫu số 3-CSDL Phụ lục I ban hành kèm theo Thông tư này;\n",
      "c) Đối với bảo hiểm phi nhân thọ (trừ bảo hiểm bắt buộc trách nhiệm dân sự của chủ xe cơ giới, bảo\n",
      "hiểm cháy, nổ bắt buộc, bảo hiểm bắt buộc trong hoạt động đầu tư xây dựng, bảo hiểm nông\n",
      "ng...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Result 3 [Score: 0.6780]\n",
      "From: Thông tư tt67, Điều 56\n",
      "Text excerpt: Điều 56. Công khai thông tin\n",
      "1. Doanh nghiệp môi giới bảo hiểm có trách nhiệm đăng tải thông tin theo quy định tại Điều 49 của Thông\n",
      "tư này đối với các nội dung phải công khai thông tin theo quy định tại khoản 8 Điều 138 Luật Kinh doanh\n",
      "bảo hiểm.\n",
      "2. ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "QUERY: 'Điều 4 quy định về gì'\n",
      "================================================================================\n",
      "Searching for: 'Điều 4 quy định về gì'\n",
      "Extracted entities: dieu: ['4'], keywords: ['định', 'quy']\n",
      "Found 2 initial results\n",
      "After strict filtering: 2 results\n",
      "Filtered to 2 most relevant results\n",
      "\n",
      "Result 1 [Score: 1.2860]\n",
      "From: Thông tư tt50, Điều 4\n",
      "Text excerpt: ... điện tử, doanh nghiệp bảo hiểm phải tuân thủ các quy\n",
      "định của Luật Giao dịch điện tử và các văn bản hướng dẫn thi hành; Giấy chứng nhận bảo hiểm điện tử\n",
      "phải tuân thủ đầy đủ các quy định hiện hành và phản ánh đầy đủ các nội dung quy định tại khoản 2 Điều\n",
      "này.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Result 2 [Score: 1.2530]\n",
      "From: Thông tư tt67, Điều 4\n",
      "Text excerpt: ... bảo hiểm được thực hiện toàn bộ hay\n",
      "một phần của quy trình cung cấp dịch vụ, sản phẩm bảo hiểm bằng phương tiện điện tử có kết nối với\n",
      "mạng internet, mạng viễn thông di động hoặc các mạng mở khác nhằm cung cấp dịch vụ, sản phẩm bảo\n",
      "hiểm trên môi trường mạng.\n",
      "2. ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "QUERY: 'Điều 2 và Điều 3 trong thông tư 67 bao gồm những gì'\n",
      "================================================================================\n",
      "Searching for: 'Điều 2 và Điều 3 trong thông tư 67 bao gồm những gì'\n",
      "Extracted entities: dieu: ['2', '3'], thong_tu: ['tt67'], keywords: ['gồm', 'bao']\n",
      "Found 54 initial results\n",
      "After strict filtering: 2 results\n",
      "Filtered to 2 most relevant results\n",
      "\n",
      "Result 1 [Score: 1.5865]\n",
      "From: Thông tư tt67, Điều 3\n",
      "Text excerpt: Điều 3. Cung cấp và cập nhật thông tin\n",
      "1. Thông tin quy định tại điểm c khoản 1 Điều 7 Nghị định số 46/2023/NĐ-CP được quy định chi tiết\n",
      "tại Mẫu số 1-CSDL Phụ lục I ban hành kèm theo Thông tư này.\n",
      "2. ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Result 2 [Score: 1.4922]\n",
      "From: Thông tư tt67, Điều 2\n",
      "Text excerpt: Điều 2. Đối tượng áp dụng\n",
      "1. Doanh nghiệp bảo hiểm phi nhân thọ, doanh nghiệp bảo hiểm nhân thọ, doanh nghiệp bảo hiểm sức\n",
      "khỏe (sau đây gọi là doanh nghiệp bảo hiểm), doanh nghiệp tái bảo hiểm, đại lý bảo hiểm, doanh nghiệp\n",
      "môi giới bảo hiểm, tổ chức, cá nhân cung cấp dịch vụ phụ trợ bảo hiểm, tổ chức tương hỗ cung cấp bảo\n",
      "hiểm vi mô.\n",
      "2. ...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"Connected to Qdrant at: {QDRANT_URL}\")\n",
    "\n",
    "run_example_queries()  \n",
    "\n",
    "#interactive_search()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
