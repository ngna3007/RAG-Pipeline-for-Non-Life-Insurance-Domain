{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import dotenv\n",
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "\n",
    "#load environment variables\n",
    "dotenv.load_dotenv(\".env.local\")\n",
    "\n",
    "#initialize gemini api\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "#set the model to use - we know gemini-1.5-flash works\n",
    "MODEL_NAME = \"models/gemini-1.5-flash\"\n",
    "print(f\"Using model: {MODEL_NAME}\")\n",
    "\n",
    "#import the retrieval module\n",
    "from retrieval import search_legal_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format the retrieved documents into a readable string for the llm\n",
    "def format_documents(results):\n",
    "    if not results:\n",
    "        return \"No documents found.\"\n",
    "    \n",
    "    #sort results by score if they aren't already\n",
    "    sorted_results = sorted(results, key=lambda x: x.score, reverse=True)\n",
    "    \n",
    "    formatted_docs = \"\"\n",
    "    for i, result in enumerate(sorted_results):\n",
    "        metadata = result.payload.get('metadata', {})\n",
    "        text = result.payload.get('text', '')\n",
    "        thong_tu = metadata.get('Th√¥ng t∆∞', 'Unknown')\n",
    "        dieu = metadata.get('ƒêi·ªÅu', 'Unknown')\n",
    "        score = result.score\n",
    "        \n",
    "        formatted_docs += f\"T√†i li·ªáu #{i+1} (ƒê·ªô tin c·∫≠y: {score:.4f}):\\n\"\n",
    "        formatted_docs += f\"Ngu·ªìn: Th√¥ng t∆∞ {thong_tu}, ƒêi·ªÅu {dieu}\\n\"\n",
    "        formatted_docs += f\"N·ªôi dung: {text}\\n\\n\"\n",
    "    \n",
    "    #add a guidance note for the llm\n",
    "    formatted_docs += \"L∆∞u √Ω: H√£y ∆∞u ti√™n th√¥ng tin t·ª´ c√°c t√†i li·ªáu c√≥ ƒë·ªô tin c·∫≠y cao h∆°n khi tr·∫£ l·ªùi c√¢u h·ªèi.\\n\\n\"\n",
    "    \n",
    "    return formatted_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create full prompt for the model\n",
    "def create_prompt(query, documents):\n",
    "    system_instructions = \"\"\"\n",
    "    B·∫°n l√† tr·ª£ l√Ω ph√°p l√Ω chuy√™n v·ªÅ lu·∫≠t ph√°p Vi·ªát Nam. Nhi·ªám v·ª• c·ªßa b·∫°n l√† gi√∫p ng∆∞·ªùi d√πng hi·ªÉu r√µ c√°c quy ƒë·ªãnh ph√°p lu·∫≠t \n",
    "    d·ª±a tr√™n c√°c t√†i li·ªáu ph√°p l√Ω ƒë∆∞·ª£c cung c·∫•p. H√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng d·ª±a tr√™n th√¥ng tin trong c√°c t√†i li·ªáu.\n",
    "    \n",
    "    Nguy√™n t·∫Øc tr·∫£ l·ªùi:\n",
    "    1. Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin t·ª´ c√°c t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p trong ph·∫ßn ng·ªØ c·∫£nh\n",
    "    2. N·∫øu th√¥ng tin kh√¥ng ƒë·ªß ƒë·ªÉ tr·∫£ l·ªùi, h√£y n√™u r√µ v√† kh√¥ng ƒë∆∞a ra ph√°n ƒëo√°n\n",
    "    3. Tr√≠ch d·∫´n c·ª• th·ªÉ c√°c ƒëi·ªÅu kho·∫£n li√™n quan ƒë·ªÉ h·ªó tr·ª£ c√¢u tr·∫£ l·ªùi\n",
    "    4. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát v·ªõi ng√¥n ng·ªØ d·ªÖ hi·ªÉu, tr√°nh thu·∫≠t ng·ªØ ph·ª©c t·∫°p khi c√≥ th·ªÉ\n",
    "    5. Kh√¥ng t·∫°o ra th√¥ng tin kh√¥ng c√≥ trong t√†i li·ªáu, kh√¥ng ƒë∆∞a ra t∆∞ v·∫•n ph√°p l√Ω c√° nh√¢n\n",
    "    6. Lu√¥n tr√≠ch d·∫´n ngu·ªìn (Th√¥ng t∆∞ s·ªë m·∫•y, ƒêi·ªÅu m·∫•y) khi ƒë∆∞a ra th√¥ng tin\n",
    "    \"\"\"\n",
    "    \n",
    "    full_prompt = f\"{system_instructions}\\n\\nC√¢u h·ªèi: {query}\\n\\nNg·ªØ c·∫£nh t·ª´ c√°c t√†i li·ªáu ph√°p l√Ω:\\n{documents}\\n\\nD·ª±a v√†o ng·ªØ c·∫£nh tr√™n, h√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch ch√≠nh x√°c v√† ƒë·∫ßy ƒë·ªß.\"\n",
    "    \n",
    "    return full_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, documents):\n",
    "    try:\n",
    "        #format documents and create the prompt\n",
    "        formatted_docs = format_documents(documents)\n",
    "        full_prompt = create_prompt(query, formatted_docs)\n",
    "        \n",
    "        #initialize the model\n",
    "        model = genai.GenerativeModel(MODEL_NAME)\n",
    "        \n",
    "        #generate the response\n",
    "        try:\n",
    "            response = model.generate_content(\n",
    "                full_prompt,\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    temperature=0.3,\n",
    "                    max_output_tokens=1024,\n",
    "                    top_p=0.95,\n",
    "                )\n",
    "            )\n",
    "            return response.text\n",
    "        except Exception as config_error:\n",
    "            print(f\"Error with generation config, trying simpler call: {config_error}\")\n",
    "            response = model.generate_content(full_prompt)\n",
    "            return response.text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {str(e)}\")\n",
    "        return f\"ƒê√£ x·∫£y ra l·ªói khi t·∫°o ph·∫£n h·ªìi: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sources_for_display(documents, processing_time):\n",
    "    sources_text = f\"### Ngu·ªìn t√†i li·ªáu tham kh·∫£o (Th·ªùi gian x·ª≠ l√Ω: {processing_time:.2f}s)\\n\\n\"\n",
    "    \n",
    "    for i, doc in enumerate(documents):\n",
    "        metadata = doc.payload.get('metadata', {})\n",
    "        thong_tu = metadata.get('Th√¥ng t∆∞', 'Unknown')\n",
    "        dieu = metadata.get('ƒêi·ªÅu', 'Unknown')\n",
    "        \n",
    "        #extract a short preview of the document\n",
    "        text = doc.payload.get('text', '')\n",
    "        excerpt = text[:200] + \"...\" if len(text) > 200 else text\n",
    "        \n",
    "        #format the source information\n",
    "        sources_text += f\"**Ngu·ªìn #{i+1}:** Th√¥ng t∆∞ {thong_tu}, ƒêi·ªÅu {dieu} (ƒê·ªô tin c·∫≠y: {doc.score:.4f})\\n\\n\"\n",
    "        sources_text += f\"*Tr√≠ch ƒëo·∫°n:* {excerpt}\\n\\n---\\n\\n\"\n",
    "    \n",
    "    return sources_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process user query and return answer with its sources\n",
    "def process_query(query, num_docs = 5):\n",
    "    if not query.strip():\n",
    "        return \"Vui l√≤ng nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n.\", \"\"\n",
    "    \n",
    "    try:\n",
    "        #track processing time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        #step 1, retrieve documents\n",
    "        print(f\"Retrieving documents for query: {query}\")\n",
    "        retrieved_docs = search_legal_documents(query, limit=num_docs)\n",
    "        \n",
    "        if not retrieved_docs:\n",
    "            return \"Kh√¥ng t√¨m th·∫•y t√†i li·ªáu li√™n quan ƒë·∫øn c√¢u h·ªèi c·ªßa b·∫°n.\", \"\"\n",
    "        \n",
    "        #step 2, generate answer\n",
    "        print(f\"Generating response with {len(retrieved_docs)} documents\")\n",
    "        answer = generate_response(query, retrieved_docs)\n",
    "        \n",
    "        #step 3, format sources for display\n",
    "        sources_text = format_sources_for_display(retrieved_docs, time.time() - start_time)\n",
    "        \n",
    "        return answer, sources_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_message = f\"ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω c√¢u h·ªèi: {str(e)}\"\n",
    "        print(error_message)\n",
    "        return error_message, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create and configure the gradio interface\n",
    "def create_interface():\n",
    "    with gr.Blocks(title=\"Tr·ª£ l√Ω Ph√°p l√Ω Vi·ªát Nam\", theme=gr.themes.Soft()) as demo:\n",
    "        #header\n",
    "        gr.Markdown(\n",
    "            f\"\"\"\n",
    "            # üáªüá≥ Tr·ª£ l√Ω Ph√°p l√Ω\n",
    "            \n",
    "            H·ªá th·ªëng n√†y s·ª≠ d·ª•ng c√¥ng ngh·ªá RAG (Retrieval-Augmented Generation) ƒë·ªÉ tr·∫£ l·ªùi \n",
    "            c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn t√†i li·ªáu ph√°p l√Ω.\n",
    "            \n",
    "            *Model: {MODEL_NAME}*\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        #input area\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=4):\n",
    "                query_input = gr.Textbox(\n",
    "                    label=\"C√¢u h·ªèi c·ªßa b·∫°n\", \n",
    "                    placeholder=\"V√≠ d·ª•: ƒêi·ªÅu 4 trong th√¥ng t∆∞ 67 quy ƒë·ªãnh v·ªÅ g√¨?\",\n",
    "                    lines=2\n",
    "                )\n",
    "            \n",
    "            with gr.Column(scale=1):\n",
    "                num_docs = gr.Slider(\n",
    "                    minimum=1, \n",
    "                    maximum=10, \n",
    "                    value=5, \n",
    "                    step=1, \n",
    "                    label=\"S·ªë l∆∞·ª£ng t√†i li·ªáu\"\n",
    "                )\n",
    "        \n",
    "        #ssubmit button\n",
    "        submit_btn = gr.Button(\"G·ª≠i\", variant=\"primary\")\n",
    "        \n",
    "        #ooutput area\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=3):\n",
    "                answer_output = gr.Markdown(label=\"C√¢u tr·∫£ l·ªùi\")\n",
    "            with gr.Column(scale=2):\n",
    "                sources_output = gr.Markdown(label=\"Ngu·ªìn t√†i li·ªáu\")\n",
    "        \n",
    "        #eevent handlers\n",
    "        submit_btn.click(\n",
    "            fn=process_query, \n",
    "            inputs=[query_input, num_docs], \n",
    "            outputs=[answer_output, sources_output]\n",
    "        )\n",
    "        query_input.submit(\n",
    "            fn=process_query, \n",
    "            inputs=[query_input, num_docs], \n",
    "            outputs=[answer_output, sources_output]\n",
    "        )\n",
    "        \n",
    "        #eexample questions\n",
    "        gr.Examples(\n",
    "            examples=[\n",
    "                [\"Ph√≠ b·∫£o hi·ªÉm xe c∆° gi·ªõi l√† g√¨?\"],\n",
    "                [\"ƒêi·ªÅu 4 trong th√¥ng t∆∞ 67 quy ƒë·ªãnh v·ªÅ g√¨?\"],\n",
    "                [\"ƒêi·ªÅu 2 v√† ƒêi·ªÅu 3 trong th√¥ng t∆∞ 67 bao g·ªìm nh·ªØng g√¨?\"]\n",
    "            ],\n",
    "            inputs=query_input\n",
    "        )\n",
    "        \n",
    "    return demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = create_interface()\n",
    "demo.launch(share=True)  #set share=True to create a public link"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
